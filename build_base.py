import os
# ==========================================
# ğŸ‘‡ è¿˜æ˜¯å…ˆæ¸…ç©ºä»£ç†ï¼Œé˜²æ­¢ç½‘ç»œæŠ¥é”™
os.environ["http_proxy"] = ""
os.environ["https_proxy"] = ""
os.environ["HTTP_PROXY"] = ""
os.environ["HTTPS_PROXY"] = ""
# ==========================================

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# 1. è®¾ç½® Key (è¿™é‡Œæˆ‘ä»¬è¦ç”¨ DeepSeek æˆ–è€…æ˜¯é€šç”¨çš„ Embedding)
# âš ï¸ æ³¨æ„ï¼šDeepSeek ç›®å‰ä¸»è¦æä¾›å¯¹è¯ï¼ŒEmbedding æœ‰æ—¶å€™ä¸ç¨³å®šã€‚
# ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬è¿™é‡Œå…ˆå°è¯•ç”¨ä¸€ä¸ªå¼€æºçš„ã€ä¸éœ€è¦Keyçš„æœ¬åœ°æ¨¡å‹ï¼Œæˆ–è€…
# å¦‚æœä½ æœ‰ OpenAI çš„ Key å¯ä»¥ç”¨ OpenAIã€‚
# è¿™é‡Œæˆ‘ä»¬æš‚æ—¶æ¼”ç¤ºâ€œè¯»å–+åˆ‡å‰²â€çš„æµç¨‹ï¼Œå…ˆä¸è°ƒç”¨ APIï¼Œç¡®ä¿åŸºæœ¬åŠŸæ‰å®ã€‚

print("1. æ­£åœ¨è¯»å– PDF æ–‡ä»¶...")
# ç¡®ä¿ä½ çš„æ¡Œé¢ä¸Šæœ‰ä¸€ä¸ªå« data.pdf çš„æ–‡ä»¶
loader = PyPDFLoader(r"C:\Users\huilai\Desktop\data.pdf")
docs = loader.load()
print(f"   æˆåŠŸè¯»å–ï¼Œè¿™ç¯‡æ–‡æ¡£ä¸€å…±æœ‰ {len(docs)} é¡µã€‚")

print("2. æ­£åœ¨åˆ‡åˆ†æ–‡æ¡£...")
# ä¸ºä»€ä¹ˆè¦åˆ‡åˆ†ï¼Ÿå› ä¸ºå¤§æ¨¡å‹ä¸€æ¬¡åƒä¸ä¸‹æ•´æœ¬ä¹¦ï¼Œè¦åˆ‡æˆå°å—ï¼ˆChunkï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,    # æ¯ä¸€å—å¤§çº¦ 500 ä¸ªå­—
    chunk_overlap=50   # å‰åé‡å  50 ä¸ªå­—ï¼ˆé˜²æ­¢å¥å­è¢«åˆ‡æ–­ï¼‰
)
splits = text_splitter.split_documents(docs)
print(f"   åˆ‡åˆ†å®Œæˆï¼åŸæ–‡æ¡£è¢«åˆ‡æˆäº† {len(splits)} ä¸ªå°å—ã€‚")

print("3. çœ‹çœ‹åˆ‡å‡ºæ¥çš„ç¬¬ä¸€å—é•¿ä»€ä¹ˆæ ·ï¼š")
print("-" * 30)
print(splits[0].page_content)
print("-" * 30)

print("ğŸ‰ æ­å–œï¼æ•°æ®é¢„å¤„ç†æµç¨‹è·‘é€šäº†ï¼")